# Getting Started with Ansible

With your VMs now running and connected to the Network, its time to prepare them for our Kubernetes deployment. Instead of doing all of this "foundational" work by running a few to many commands directly on the shell of all three nodes, we can leverage Ansible (a open-source IaC tool) to do the configuration for us using the "playbooks" in this guide.

Before we can run these Playbooks however, we have to install Ansible.

## Installing Ansible

Thankfully our minimal Rocky install has Python 3.12 install by default, we are just missing `pip` (pythons package manager) and an explict 'ansible' user to run our playbooks. Lets run the `autoAnisible.py` script located under "ansible/autoAnsible.py" to standup our Ansible "control-node" and "worker-nodes".

### Using the `autoAnsible.py` Script

Open three terminals and SSH into each new VM for the first time from your local machine - changing the user and IPs to match your deployment.
```
ssh cspears@10.99.0.10
ssh cspears@10.99.0.11
ssh cspears@10.99.0.12
```

Fetch the Installer from the public repo...
```
curl https://raw.githubusercontent.com/ToyoLandi/teleport-concept/refs/heads/main/ansible/autoAnsible.py -o autoAnsible.py
```

Run the Installer with python3 using the applicable '--control-node' or '--worker-node' arguments. 
```
# use the '--control-node' argument for the "challenger-master" node
sudo python3 autoAnsible.py --control-node

# use the '--worker-node' argument for the "challenger-worker-1" and "challenger-worker-2" nodes
sudo python3 autoAnsible.py --worker-node
```

From our new 'ansible' users terminal of your control-node, share the public SSH Key generated by `autoAnsible` to our "worker-nodes" + the "control-node" itself after all three have been staged - **Be sure to replace the IPs with those for your environment**.
```
su ansible
ssh-copy-id -i ~/.ssh/challenger-master_rsa.pub ansible@10.99.0.10
ssh-copy-id -i ~/.ssh/challenger-master_rsa.pub ansible@10.99.0.11
ssh-copy-id -i ~/.ssh/challenger-master_rsa.pub ansible@10.99.0.12
```
>  We copy the pubkey to all three nodes to safely update its "known_host" file for the 'ansible' user, which allows the 'ansible' user to login using our custom certificates, to run our playbooks.

Finally, test our Ansible connections from the 'ansible' user terminal.
```
ansible -i ~/ansible/hosts.yaml all -m ping
```

## What's Next?
At this point, we can start building our empire quickly using Ansible. It's time to proceed to our Kubernetes deployment under the "installk8s" guide in the repo.